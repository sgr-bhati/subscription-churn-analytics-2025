{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb57f135-0686-46b2-a830-c33cbe515d0c",
   "metadata": {},
   "source": [
    "# L1 Logistics Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2124d23b-fc65-4e24-9283-ba0257228ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f71217-1640-4358-b018-114f1e9a7910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['months_subscribed',\n",
       " 'streaming_quality',\n",
       " 'subscription_type',\n",
       " 'monthly_plan_cost',\n",
       " 'app_usage_hours',\n",
       " 'last30d_usage_hours',\n",
       " 'customer_rating',\n",
       " 'promo_email_clicks',\n",
       " 'num_profiles',\n",
       " 'auto_renew',\n",
       " 'support_tickets_last6m',\n",
       " 'nps_score',\n",
       " 'gender_Male',\n",
       " 'payment_mode_Credit card (automatic)',\n",
       " 'payment_mode_Electronic check',\n",
       " 'payment_mode_Mailed check',\n",
       " 'device_type_Mobile',\n",
       " 'device_type_SmartTV',\n",
       " 'total_revenue_log']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain=load_csv('../data/processed/XTrain.csv')\n",
    "XTest=load_csv('../data/processed/XTest.csv')\n",
    "YTrain=load_csv('../data/processed/YTrain.csv')\n",
    "YTest=load_csv('../data/processed/YTest.csv')\n",
    "XTrain.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104a4016-4dd3-48cf-83f9-679cfa67cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4930 entries, 0 to 4929\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   months_subscribed                     4930 non-null   float64\n",
      " 1   streaming_quality                     4930 non-null   float64\n",
      " 2   subscription_type                     4930 non-null   float64\n",
      " 3   monthly_plan_cost                     4930 non-null   float64\n",
      " 4   app_usage_hours                       4930 non-null   float64\n",
      " 5   last30d_usage_hours                   4930 non-null   float64\n",
      " 6   customer_rating                       4930 non-null   float64\n",
      " 7   auto_renew                            4930 non-null   float64\n",
      " 8   nps_score                             4930 non-null   float64\n",
      " 9   gender_Male                           4930 non-null   float64\n",
      " 10  payment_mode_Credit card (automatic)  4930 non-null   float64\n",
      " 11  payment_mode_Electronic check         4930 non-null   float64\n",
      " 12  payment_mode_Mailed check             4930 non-null   float64\n",
      " 13  device_type_Mobile                    4930 non-null   float64\n",
      " 14  device_type_SmartTV                   4930 non-null   float64\n",
      " 15  total_revenue_log                     4930 non-null   float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 616.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Droppoing the High colinear cols for l1 logistics model is highly sensitive to the high collinearity.\n",
    "XTrain = XTrain.drop(columns=['promo_email_clicks', 'num_profiles', 'support_tickets_last6m'], errors='ignore')\n",
    "XTest = XTest.drop(columns=['promo_email_clicks', 'num_profiles', 'support_tickets_last6m'], errors='ignore')\n",
    "XTrain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074847e-d6ca-41b2-b591-1591256758a5",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8af398d-3ea1-457c-adc2-cbfb1e3869bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "--- L1 Logistic Regression Results ---\n",
      "Optimal Regularization Strength (C): 0.0464\n",
      "Cross-Validated ROC AUC on Training Data: 0.8415\n",
      "ROC AUC on Unseen Test Data: 0.8488\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.69      0.79      1552\n",
      "           1       0.49      0.84      0.62       561\n",
      "\n",
      "    accuracy                           0.73      2113\n",
      "   macro avg       0.71      0.77      0.70      2113\n",
      "weighted avg       0.81      0.73      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Set up L1 Logistic Regression with GridSearchCV ---\n",
    "\n",
    "# C is the inverse of regularization strength. Smaller C = stronger regularization (fewer features kept).\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 0, 10) # Search range from very strong to very weak regularization\n",
    "}\n",
    "\n",
    "# The L1 penalty forces coefficients of weak features to zero.\n",
    "l1_tuner = GridSearchCV(\n",
    "  # estimator=LogisticRegression(penalty='l1', solver='liblinear', random_state=16),---------------------- results are very poor because of the Class Imbalance (recall:49% only)\n",
    "    estimator=LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', random_state=16),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc', \n",
    "    cv=5, # 5-fold Cross-Validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# DataConversion Warning Fix:\n",
    "Ytest = YTest.values.ravel()\n",
    "Ytrain = YTrain.values.ravel()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "l1_tuner.fit(XTrain, Ytrain)\n",
    "\n",
    "# Final Model and Evaluation ---\n",
    "best_l1_model = l1_tuner.best_estimator_\n",
    "\n",
    "print(f\"--- L1 Logistic Regression Results ---\")\n",
    "print(f\"Optimal Regularization Strength (C): {l1_tuner.best_params_['C']:.4f}\")\n",
    "print(f\"Cross-Validated ROC AUC on Training Data: {l1_tuner.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the unseen test data\n",
    "y_prob = best_l1_model.predict_proba(XTest)[:, 1]\n",
    "test_roc_auc = roc_auc_score(Ytest, y_prob)\n",
    "print(f\"ROC AUC on Unseen Test Data: {test_roc_auc:.4f}\\n\")\n",
    "\n",
    "# Use a standard threshold (0.5) to get a classification report\n",
    "y_pred = best_l1_model.predict(XTest)\n",
    "print(classification_report(Ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c270ad03-f59c-467d-8952-01188f589141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the different Thresholds \n",
    "# thresholds = np.arange(0.30, 0.80, 0.05)\n",
    "# for t in thresholds:\n",
    "#     print(f\"-----------------------------{t}--------------------------\")\n",
    "#     y_pred_custom = (y_prob >= t).astype(int)\n",
    "#     print(classification_report(YTest, y_pred_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33a33c-8c65-449f-b64b-d31d8c977af4",
   "metadata": {},
   "source": [
    "### “Since churn is a cost-sensitive problem, we evaluated multiple probability thresholds between 0.30 and 0.80. While higher thresholds improved accuracy, they significantly reduced recall for churners. The F1-optimized thresholds range from 0.45 to 0.65, and the final choice is a business decision based on the cost function. We selected a threshold of 0.55, which maintains high churn recall (81%) while improving precision and operational efficiency. This provides the best balance between customer retention coverage and campaign cost.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee65275c-fbbf-47f0-9503-d6e0cc2f5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "--- Elastic-Net Results ---\n",
      "Best Parameters: {'C': np.float64(0.1), 'l1_ratio': 1.0}\n",
      "Best CV ROC AUC: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# Logistics ElasticNet Saga Model\n",
    "# Define the search space for Elastic-Net\n",
    "param_grid_en = {\n",
    "    # C is the inverse of regularization strength\n",
    "    'C': np.logspace(-4, 0, 5), \n",
    "    # l1_ratio controls the mix: 0=pure L2, 1=pure L1\n",
    "    'l1_ratio': [0.25, 0.5, 0.75, 1.0] \n",
    "}\n",
    "\n",
    "# Set up the Elastic-Net tuner (must use solver='saga')\n",
    "en_tuner = GridSearchCV(\n",
    "    estimator=LogisticRegression(\n",
    "        penalty='elasticnet', \n",
    "        solver='saga', \n",
    "        random_state=16, \n",
    "        class_weight='balanced', # Keep this from previous enhancement\n",
    "        max_iter=500 # Increase max_iter for 'saga' solver stability\n",
    "    ),\n",
    "    param_grid=param_grid_en,\n",
    "    scoring='roc_auc', \n",
    "    cv=5, \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "Ytest = YTest.values.ravel()\n",
    "Ytrain = YTrain.values.ravel()\n",
    "# Fit the model\n",
    "en_tuner.fit(XTrain, Ytrain)\n",
    "\n",
    "# Compare results:\n",
    "print(\"\\n--- Elastic-Net Results ---\")\n",
    "print(f\"Best Parameters: {en_tuner.best_params_}\")\n",
    "print(f\"Best CV ROC AUC: {en_tuner.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63fc3d-4502-4019-a262-836b2e99af61",
   "metadata": {},
   "source": [
    "the improvement from the elasticnet momdel is minimal(.0005) hence it suggest that L1 choice is optimal for our Dataset, now we know the best c= 0.1 hence we will rerun the pure l1 model using that value and the most optimal thersold value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054927c3-7051-4d26-b6cb-f8d99275a5df",
   "metadata": {},
   "source": [
    "# Final Logistics Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2e19a7-4109-4846-a930-03312f41d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82      1552\n",
      "           1       0.53      0.81      0.64       561\n",
      "\n",
      "    accuracy                           0.76      2113\n",
      "   macro avg       0.72      0.77      0.73      2113\n",
      "weighted avg       0.81      0.76      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimal C found from Elastic-Net:\n",
    "optimal_C = 0.1\n",
    "\n",
    "# Reruning the final L1 Model with optimal C and class balancing\n",
    "final_l1_model = LogisticRegression(penalty='l1', C=optimal_C, solver='liblinear', class_weight='balanced', random_state=16)\n",
    "\n",
    "# DataConversion Warning Fix:\n",
    "Ytest = YTest.values.ravel()\n",
    "Ytrain = YTrain.values.ravel()\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "final_l1_model.fit(XTrain, Ytrain)\n",
    "\n",
    "# Report\n",
    "y_prob = final_l1_model.predict_proba(XTest)[:, 1]\n",
    "y_pred_55 = (y_prob >= .55).astype(int)\n",
    "print(classification_report(Ytest, y_pred_55))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8c867a-09f0-48c2-ad35-76536d1bbbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with 7043 rows.\n",
      "Saved Model: ../data/processed/l1_model/final_l1_logistic_model.joblib\n",
      "Saved Predictions: ../data/processed/l1_model/l1_churn_predictions_ACTIONABLE.csv\n",
      "\n",
      "--- Delivery Complete ---\n",
      "Total Customers in Report: 2113\n",
      "Customers Flagged for Retention: 857\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Replace 'customer_id' with the EXACT name of the ID column in your processed CSV\n",
    "CUSTOMER_ID_COL = 'customer_id' \n",
    "# ---------------------\n",
    "\n",
    "# --- 1. Load the Original Processed Data (Contains IDs) ---\n",
    "df=pd.read_csv(\"../data/processed/cleaned_subscriptions_churn.csv\")\n",
    "print(f\"Loaded data with {df.shape[0]} rows.\")\n",
    "\n",
    "# Separate Target and Features\n",
    "# We use the target to ensure the split is identical to your modeling step\n",
    "y = df['subscription_canceled'].values.ravel()\n",
    "X = df.drop(columns=['subscription_canceled'])\n",
    "\n",
    "# --- 2. Re-Split to Isolate the Test Set IDs ---\n",
    "# We use the EXACT same parameters: test_size=0.2, random_state=42, stratify=y\n",
    "# We don't need to drop columns here because we only care about the indices\n",
    "X_train_orig, X_test_orig, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=16, stratify=y)\n",
    "\n",
    "# --- 3. Generate Predictions ---\n",
    "# Use your trained 'final_l1_model' and the scaled test data 'XTest'\n",
    "# (These must be currently in your memory from previous steps)\n",
    "y_prob = final_l1_model.predict_proba(XTest)[:, 1]\n",
    "\n",
    "# Apply your optimized threshold\n",
    "CHURN_THRESHOLD = 0.55\n",
    "y_pred_final = (y_prob >= CHURN_THRESHOLD).astype(int)\n",
    "\n",
    "# --- 4. Assemble the Final Data Frame ---\n",
    "# Reset index to ensure 1:1 alignment between the Original Data rows and Predictions\n",
    "X_test_orig = X_test_orig.reset_index(drop=True)\n",
    "\n",
    "results_df = X_test_orig.copy()\n",
    "results_df['True_Churn_Status'] = y_test # Add true status\n",
    "results_df['Predicted_Probability'] = y_prob # Add model probability\n",
    "results_df['Predicted_Churn_Flag'] = y_pred_final # Add final decision\n",
    "\n",
    "# --- 5. Organize Columns (Put ID First) ---\n",
    "# Moves customer_id to the first column for readability\n",
    "if CUSTOMER_ID_COL in results_df.columns:\n",
    "    cols = [CUSTOMER_ID_COL] + [c for c in results_df.columns if c != CUSTOMER_ID_COL]\n",
    "    results_df = results_df[cols]\n",
    "\n",
    "# Define output directory\n",
    "OUTPUT_DIR = \"../data/processed/l1_model\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Save Final Artifacts ---\n",
    "joblib.dump(final_l1_model,os.path.join(OUTPUT_DIR, \"final_l1_logistic_model.joblib\"))\n",
    "print(\"Saved Model:\", os.path.join(OUTPUT_DIR, \"final_l1_logistic_model.joblib\"))\n",
    "\n",
    "results_df.to_csv(os.path.join(OUTPUT_DIR, \"l1_churn_predictions_ACTIONABLE.csv\"),index=False)\n",
    "print(\"Saved Predictions:\", os.path.join(OUTPUT_DIR, \"l1_churn_predictions_ACTIONABLE.csv\"))\n",
    "\n",
    "\n",
    "# Print Summary\n",
    "print(f\"\\n--- Delivery Complete ---\")\n",
    "print(f\"Total Customers in Report: {len(results_df)}\")\n",
    "print(f\"Customers Flagged for Retention: {results_df['Predicted_Churn_Flag'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2827695a-9389-4403-b226-5e7bb81beb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final L1 Model Coefficients ---\n",
      "| Feature                              |   Coefficient |\n",
      "|:-------------------------------------|--------------:|\n",
      "| months_subscribed                    |    2.47144    |\n",
      "| payment_mode_Mailed check            |    0.328278   |\n",
      "| gender_Male                          |    0.321388   |\n",
      "| nps_score                            |    0.038091   |\n",
      "| customer_rating                      |    0          |\n",
      "| subscription_type                    |    0          |\n",
      "| monthly_plan_cost                    |    0          |\n",
      "| app_usage_hours                      |    0          |\n",
      "| total_revenue_log                    |    0          |\n",
      "| payment_mode_Credit card (automatic) |    0          |\n",
      "| last30d_usage_hours                  |    0          |\n",
      "| device_type_SmartTV                  |   -0.00134841 |\n",
      "| payment_mode_Electronic check        |   -0.00602115 |\n",
      "| device_type_Mobile                   |   -0.0901755  |\n",
      "| auto_renew                           |   -0.722399   |\n",
      "| streaming_quality                    |   -1.68016    |\n",
      "\n",
      "--- Top 5 Churn Drivers ---\n",
      "| Feature                   |   Coefficient |\n",
      "|:--------------------------|--------------:|\n",
      "| months_subscribed         |      2.47144  |\n",
      "| payment_mode_Mailed check |      0.328278 |\n",
      "| gender_Male               |      0.321388 |\n",
      "| nps_score                 |      0.038091 |\n",
      "\n",
      "--- Top 5 Retention Drivers ---\n",
      "| Feature                       |   Coefficient |\n",
      "|:------------------------------|--------------:|\n",
      "| device_type_SmartTV           |   -0.00134841 |\n",
      "| payment_mode_Electronic check |   -0.00602115 |\n",
      "| device_type_Mobile            |   -0.0901755  |\n",
      "| auto_renew                    |   -0.722399   |\n",
      "| streaming_quality             |   -1.68016    |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define feature_list\n",
    "feature_list = XTest.columns.tolist()  # or X_test_scaled.columns.tolist()\n",
    "\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_list,\n",
    "    'Coefficient': final_l1_model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n--- Final L1 Model Coefficients ---\")\n",
    "print(coefficients_df.to_markdown(index=False))\n",
    "\n",
    "churn_drivers = coefficients_df[coefficients_df['Coefficient'] > 0].head(5)\n",
    "retention_drivers = coefficients_df[coefficients_df['Coefficient'] < 0].tail(5)\n",
    "\n",
    "print(\"\\n--- Top 5 Churn Drivers ---\")\n",
    "print(churn_drivers.to_markdown(index=False))\n",
    "\n",
    "print(\"\\n--- Top 5 Retention Drivers ---\")\n",
    "print(retention_drivers.to_markdown(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
